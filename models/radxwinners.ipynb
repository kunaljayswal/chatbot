{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunilrai486/radx_winners_bot/blob/main/models/radxwinners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNP3FSjAj_Ff"
      },
      "source": [
        "## installing libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSDirQtFiUbZ",
        "outputId": "43111df0-9c44-4014-850c-bb00329e8da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.32-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m678.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.6)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n",
            "Installing collected packages: fastavro, backoff, tiktoken, cohere\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.32 fastavro-1.8.2 tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install cohere tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bogr807X2F-5",
        "outputId": "ecbd6c92-c5d2-48d1-abbf-d70d9f667cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llmx==0.0.15a0 in /usr/local/lib/python3.10/dist-packages (0.0.15a0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (1.10.13)\n",
            "Collecting openai (from llmx==0.0.15a0)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (0.5.1)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (5.6.3)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (4.32)\n",
            "Requirement already satisfied: google.auth in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (2.17.3)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llmx==0.0.15a0) (6.0.1)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx==0.0.15a0) (3.8.6)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx==0.0.15a0) (2.2.1)\n",
            "Requirement already satisfied: fastavro==1.8.2 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx==0.0.15a0) (1.8.2)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx==0.0.15a0) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx==0.0.15a0) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx==0.0.15a0) (2.0.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx==0.0.15a0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx==0.0.15a0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx==0.0.15a0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx==0.0.15a0) (4.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai->llmx==0.0.15a0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llmx==0.0.15a0) (4.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llmx==0.0.15a0) (2023.6.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->llmx==0.0.15a0) (8.1.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->llmx==0.0.15a0) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere->llmx==0.0.15a0) (3.17.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google.auth->llmx==0.0.15a0) (0.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere->llmx==0.0.15a0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere->llmx==0.0.15a0) (2023.7.22)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "pip install llmx==0.0.15a0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQu1Fq4UiG_z",
        "outputId": "44f394f7-5f3d-4769-a1ee-606e1ac2b4c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyautogen~=0.1.0\n",
            "  Downloading pyautogen-0.1.13-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from pyautogen~=0.1.0) (5.6.3)\n",
            "Collecting flaml (from pyautogen~=0.1.0)\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<1 in /usr/local/lib/python3.10/dist-packages (from pyautogen~=0.1.0) (0.28.1)\n",
            "Collecting python-dotenv (from pyautogen~=0.1.0)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen~=0.1.0) (2.3.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<1->pyautogen~=0.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<1->pyautogen~=0.1.0) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<1->pyautogen~=0.1.0) (3.8.6)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.10/dist-packages (from flaml->pyautogen~=0.1.0) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen~=0.1.0) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen~=0.1.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen~=0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1->pyautogen~=0.1.0) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen~=0.1.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen~=0.1.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen~=0.1.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen~=0.1.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen~=0.1.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1->pyautogen~=0.1.0) (1.3.1)\n",
            "Installing collected packages: python-dotenv, flaml, pyautogen\n",
            "Successfully installed flaml-2.1.1 pyautogen-0.1.13 python-dotenv-1.0.0\n"
          ]
        }
      ],
      "source": [
        " %pip install pyautogen~=0.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_KrPhUZ42Av",
        "outputId": "0e7d1042-9f24-4c3b-9b60-46c956570aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYzb0WwNkEnn"
      },
      "source": [
        "## setting up models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zMpX7qIkLAf",
        "outputId": "d80110e3-0124-4231-9a0e-1cffff0f7c61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:The specified config_list file 'OAI_CONFIG_LIST' does not exist.\n"
          ]
        }
      ],
      "source": [
        "import autogen\n",
        "\n",
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-3.5-turbo\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3fGdvDQmrVg"
      },
      "outputs": [],
      "source": [
        "config_list = [\n",
        "    {\n",
        "        'model': 'gpt-3.5-turbo',\n",
        "        'api_key': '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',\n",
        "    },\n",
        "]\n",
        "llm_config={\n",
        "    \"request_timeout\": 600,\n",
        "    \"seed\": 42,\n",
        "    \"config_list\": config_list,\n",
        "    \"temperature\": 0\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV_w83vSqS_A",
        "outputId": "6e71c5d0-e97a-4a43-fa50-732c18585189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_proxy (to REX):\n",
            "\n",
            "generate a simple task for a new pthython learner\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "REX (to user_proxy):\n",
            "\n",
            "Sure! Here's a simple task for a new Python learner:\n",
            "\n",
            "Task: Write a program that asks the user for their name and then prints a personalized greeting.\n",
            "\n",
            "Steps:\n",
            "1. Prompt the user to enter their name.\n",
            "2. Read the user's input and store it in a variable.\n",
            "3. Print a greeting message that includes the user's name.\n",
            "\n",
            "Example Output:\n",
            "```\n",
            "Enter your name: John\n",
            "Hello, John! Nice to meet you.\n",
            "```\n",
            "\n",
            "Give it a try and let me know if you have any questions or need further guidance!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is unknown)...\n",
            "user_proxy (to REX):\n",
            "\n",
            "exitcode: 1 (execution failed)\n",
            "Code output: \n",
            "unknown language unknown\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "REX (to user_proxy):\n",
            "\n",
            "I apologize for the confusion. It seems that there was an error in the execution of the code. Could you please provide the code you used so that I can assist you in identifying and resolving the issue?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "[autogen.oai.completion: 10-26 18:11:40] {252} INFO - retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 222, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-E15ddHaTX50FIblJpxUasdYI on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:autogen.oai.completion:retrying in 10 seconds...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogen/oai/completion.py\", line 222, in _get_response\n",
            "    response = openai_completion.create(**config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
            "    return super().create(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\", line 155, in create\n",
            "    response, _, api_key = requestor.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 299, in request\n",
            "    resp, got_stream = self._interpret_response(result, stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 710, in _interpret_response\n",
            "    self._interpret_response_line(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\", line 775, in _interpret_response_line\n",
            "    raise self.handle_error_response(\n",
            "openai.error.RateLimitError: Rate limit reached for gpt-3.5-turbo in organization org-E15ddHaTX50FIblJpxUasdYI on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_proxy (to REX):\n",
            "\n",
            "I apologize for the confusion. Here's the code for the task:\n",
            "\n",
            "```python\n",
            "# Prompt the user to enter their name\n",
            "name = input(\"Enter your name: \")\n",
            "\n",
            "# Print a personalized greeting\n",
            "print(\"Hello, \" + name + \"! Nice to meet you.\")\n",
            "```\n",
            "\n",
            "Please try running this code and let me know if you encounter any errors or need further assistance.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "REX (to user_proxy):\n",
            "\n",
            "Thank you for providing the code. It looks correct, and there shouldn't be any errors in its execution. Let's try running it again.\n",
            "\n",
            "Make sure you are running the code in a Python environment or IDE. Copy the code into a Python file (with a .py extension) and run it. You should see a prompt asking for your name, and after entering your name, the program should print a personalized greeting.\n",
            "\n",
            "If you are still encountering any issues or errors, please let me know the specific error message you are receiving, and I'll be happy to help you troubleshoot it.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "User: exit\n"
          ]
        }
      ],
      "source": [
        "class TaskMaster:\n",
        "    def __init__(self, task_prompt):\n",
        "        self.task_prompt = task_prompt\n",
        "        self.taskMaster = autogen.AssistantAgent(\n",
        "          name=\"REX\",\n",
        "          llm_config=llm_config,\n",
        "          system_message=\"\"\"Your role is crucial. Provide clear task descriptions. Guide, but don't give direct solutions.\n",
        "            Identify errors, explain concepts, and clarify doubts. Encourage positive efforts and adjust challenges appropriately.\n",
        "            After completion, give constructive feedback. Foster a learning environment and empower participants to learn through active problem-solving.\"\"\"\n",
        "            )\n",
        "        self.user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"user_proxy\",\n",
        "    human_input_mode=\"NEVER\",\n",
        "    max_consecutive_auto_reply=2,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
        "    code_execution_config={\"work_dir\": \"web\"},\n",
        "    llm_config=llm_config,\n",
        "    system_message=\"\"\"dont do any thing just print what the AssistantAgent returnes\"\"\"\n",
        ")\n",
        "\n",
        "    def process_task(self):\n",
        "        self.user_proxy.initiate_chat(\n",
        "             self.taskMaster,\n",
        "               message=self.task_prompt\n",
        "        )\n",
        "\n",
        "    def ask_for_clarification(self, question):\n",
        "         self.user_proxy.initiate_chat(\n",
        "              self.taskMaster,\n",
        "               message = question\n",
        "        )\n",
        "    def send_message(self, message):\n",
        "        response = autogen.submit_code(self.taskMaster, message)\n",
        "        return response\n",
        "\n",
        "# Sample task prompt\n",
        "task_prompt = \"generate a simple task for a new pthython learner\"\n",
        "task_master = TaskMaster(task_prompt)\n",
        "task_master.process_task();\n",
        "while True:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input == \"exit\":\n",
        "      break\n",
        "    task_master.ask_for_clarification(user_input)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FyPWb3dMnMg",
        "outputId": "a065008a-2ce6-49ce-c3db-243120ff0a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
            "  \"id\": \"cmpl-8DznMB6KxfqZZQimd8xrqhHbn4BjY\",\n",
            "  \"object\": \"text_completion\",\n",
            "  \"created\": 1698346496,\n",
            "  \"model\": \"text-davinci-003\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"text\": \" in detail.\\n\\nExample:\\n\\nHello and welcome to the Python learning experience! \\n\\nYour first task is to create a program that prints out \\\"Hello, World!\\\" \\n\\nTo do this, you'll need to open up a text editor program such as TextEdit (for Mac users) or Notepad (for Windows users). Once you have opened up your text editor, simply type the following line of code into the text editor:\\n\\nprint(\\\"Hello, World!\\\")\\n\\nOnce you have saved the file, you can access it using the Python command line environment. To do this, open up the command line interface and type \\\"python\\\" followed by the name of the file you saved. This will execute your program and result in it outputting the text \\\"Hello, World!\\\" in the command line. Congratulations, you have successfully written your first program in Python!\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 82,\n",
            "    \"completion_tokens\": 181,\n",
            "    \"total_tokens\": 263\n",
            "  }\n",
            "}\n",
            "REX: REX is an artificial intelligence platform that helps organizations and individuals make better decisions. It is powered by a combination of machine learning and natural language processing technologies. REX can analyze data and provide insights in real-time. It can recognize and classify patterns in data which can be used to make decisions quickly and accurately. It can also be used to track and monitor the progress of projects and teams, and alert managers when something is off track. REX is used by a wide range of organizations, from small businesses to large enterprises.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = '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'\n",
        "system_message=\"\"\"Your role is crucial. Provide clear task descriptions. Guide, but don't give direct solutions.\n",
        "Identify errors, explain concepts, and clarify doubts. Encourage positive efforts and adjust challenges appropriately.\n",
        "After completion, give constructive feedback. Foster a learning environment and empower participants to learn through active problem-solving.\"\"\"\n",
        "\n",
        "task_prompt = \"start by greating and generate a simple task for a new python learner and explain it\"\n",
        "# Define a function for the chat\n",
        "def chat_with_openai():\n",
        "    response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",\n",
        "            prompt=system_message + task_prompt,\n",
        "            max_tokens=1000\n",
        "        )\n",
        "    print(response)\n",
        "    while True:\n",
        "        user_input = input(\"You: \")  # Get user input\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"text-davinci-003\",\n",
        "            prompt=f\"You: {user_input}\\nREX:\",\n",
        "            max_tokens=150\n",
        "        )\n",
        "        ai_response = response.choices[0].text.strip()\n",
        "\n",
        "        print(\"REX:\", ai_response)  # Print AI's response\n",
        "\n",
        "# Start the chat\n",
        "chat_with_openai()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}